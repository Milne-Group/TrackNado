{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import re\n",
    "from typing import Dict, Tuple, Union, List, Literal\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import trackhub\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seqnado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqnado_directory = pathlib.Path(\n",
    "    \"/ceph/project/milne_group/asmith/ChIP_seq/100323_CM_293TMA4_iALL_DF/2023-03-13_mouse_mapping/\"\n",
    ").absolute()\n",
    "bigwigs = list(seqnado_directory.glob(\"bigwigs/deeptools/*.bigWig\"))\n",
    "bed = list(seqnado_directory.glob(\"peaks/lanceotron/*.bed\"))\n",
    "bb = list(seqnado_directory.glob(\"peaks/lanceotron/*.bigBed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = bigwigs + bed + bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubFiles:\n",
    "    def __init__(\n",
    "        self,\n",
    "        files: Union[List[str], List[pathlib.Path], pd.DataFrame],\n",
    "        infer_subgroups: bool = False,\n",
    "        infer_attributes: bool = False,\n",
    "        deduplicate: bool = False,\n",
    "        convert_files: bool = False,\n",
    "        chromosome_sizes: Union[pathlib.Path, str] = \"\",\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "\n",
    "        self.files = self.get_file_attributes(files)  # type: ignore\n",
    "\n",
    "        if (self.files[\"ext\"] == \"bed\").any() and not convert_files:\n",
    "            raise ValueError(\n",
    "                \"BED files detected. Please set convert_files=True to convert to BigBed\"\n",
    "            )\n",
    "        else:\n",
    "            self.convert_tracks_to_ucsc_format(chrom_sizes=chromosome_sizes, outdir=\".\")\n",
    "\n",
    "        if deduplicate:\n",
    "            self.fix_duplicate_names()\n",
    "\n",
    "        if infer_attributes:\n",
    "            self.files = self.infer_attributes_from_file_names()\n",
    "\n",
    "        self.subgroup_columns = (\n",
    "            self.infer_subgroup_columns() if infer_subgroups else None\n",
    "        )\n",
    "\n",
    "    def get_file_attributes(\n",
    "        self, files: Union[pd.DataFrame, List[Union[str, pathlib.Path]]]\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        if isinstance(files, pd.DataFrame):\n",
    "            assert \"fn\" in files.columns, \"DataFrame must have a column named 'fn'\"\n",
    "            df = files\n",
    "        else:\n",
    "            df = pd.Series(files).to_frame(\"fn\")\n",
    "\n",
    "        paths = [pathlib.Path(fn) for fn in df[\"fn\"].values]\n",
    "        df[\"path\"] = [str(p.absolute().resolve()) for p in paths]\n",
    "        df[\"basename\"] = [p.name for p in paths]\n",
    "        df[\"name\"] = [p.stem for p in paths]\n",
    "        df[\"ext\"] = [p.suffix.strip(\".\") for p in paths]\n",
    "        return df\n",
    "\n",
    "    def infer_subgroup_columns(self) -> List[str]:\n",
    "        return self.files.columns.difference(\n",
    "            [\"fn\", \"path\", \"basename\", \"name\", \"ext\"]\n",
    "        ).tolist()\n",
    "\n",
    "    def fix_duplicate_names(self):\n",
    "        duplicate_counts = defaultdict(int)\n",
    "\n",
    "        for row in self.files.itertuples():\n",
    "            duplicate_counts[row.basename] += 1\n",
    "            if duplicate_counts[row.basename] > 1:\n",
    "                name = f\"{row.name}_{duplicate_counts[row.basename]}\"\n",
    "                basename = f\"{row.basename}_{duplicate_counts[row.basename]}.{row.ext}\"\n",
    "                self.files.loc[row.Index, \"name\"] = name\n",
    "                self.files.loc[row.Index, \"basename\"] = basename\n",
    "\n",
    "    def convert_tracks_to_ucsc_format(\n",
    "        self, chrom_sizes: Union[str, pathlib.Path], outdir: Union[str, pathlib.Path]\n",
    "    ) -> None:\n",
    "        \"\"\"Convert tracks to UCSC format\"\"\"\n",
    "\n",
    "        assert pathlib.Path(\n",
    "            chrom_sizes\n",
    "        ).exists(), f\"Chromosome sizes file {chrom_sizes} does not exist\"\n",
    "\n",
    "        outdir = pathlib.Path(outdir)\n",
    "        outdir.mkdir(exist_ok=True)\n",
    "\n",
    "        # convert bed to bigBed\n",
    "        bed_files = self.files[self.files[\"ext\"] == \"bed\"][\"fn\"].values\n",
    "        for bed_file in bed_files:\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"bedToBigBed\",\n",
    "                    str(bed_file),\n",
    "                    str(chrom_sizes),\n",
    "                    f\"{outdir.joinpath(bed_file.with_suffix(''))}.bigBed\",\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        # Remove the original bed files from the dataframe\n",
    "        self.files = self.files[self.files[\"ext\"] != \"bed\"]\n",
    "\n",
    "\n",
    "    def infer_attributes_from_file_names(\n",
    "        self,\n",
    "        regex: str = r\"(?P<sample_name>.*?)(?:_(?P<antibody>.*?))?(?:_(?P<replicate>[0-9]+))?$\",\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Infer attributes from file names using a regex\"\"\"\n",
    "\n",
    "        df = self.files.copy()\n",
    "        df_attributes = df[\"name\"].str.extract(regex)\n",
    "\n",
    "        # Remove any columns that are all NaN\n",
    "        df_attributes = df_attributes.loc[:, df_attributes.notnull().any()]\n",
    "\n",
    "        return df.join(df_attributes)\n",
    "\n",
    "\n",
    "class HubDesign:\n",
    "    def __init__(\n",
    "        self,\n",
    "        details: pd.DataFrame,\n",
    "        color_by: List[str] = None,\n",
    "        subgroup_by: List[str] = None,\n",
    "        overlay_by: List[str] = None,\n",
    "        supertrack_by: List[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        self.details = details\n",
    "        self._supertrack_columns = supertrack_by\n",
    "        self._overlay_columns = overlay_by\n",
    "        self._subgroup_columns = subgroup_by\n",
    "        self._color_columns = color_by\n",
    "\n",
    "        self._add_subgroupings(supergroup_by=supertrack_by, subgroup_by=subgroup_by)\n",
    "\n",
    "        self.super_tracks = self._get_super_tracks()\n",
    "        self._add_supertrack_indicators()\n",
    "\n",
    "        self.composite_tracks = self._get_composite_tracks()\n",
    "        self._add_composite_track_indicators()\n",
    "\n",
    "        self.overlay_tracks = self._get_overlay_tracks()\n",
    "        self._add_overlay_track_indicators()\n",
    "\n",
    "        self._add_track_colors(color_by=color_by)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, files: List[pathlib.Path], **kwargs) -> \"HubDesign\":\n",
    "        hub_files = HubFiles(files, **kwargs)\n",
    "\n",
    "        extra_kwargs = dict()\n",
    "        if hub_files.subgroup_columns:\n",
    "            extra_kwargs[\"subgroup_by\"] = hub_files.subgroup_columns\n",
    "\n",
    "\n",
    "        return cls(hub_files.files, **kwargs, **extra_kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_design(cls, design: pd.DataFrame, **kwargs) -> \"HubDesign\":\n",
    "        design = design.copy()\n",
    "        design = HubFiles(design, **kwargs).files\n",
    "        return cls(design, **kwargs)\n",
    "\n",
    "    def _add_track_colors(\n",
    "        self,\n",
    "        color_by: Union[str, List[str]] = None,\n",
    "        pallet: str = \"tab20\",\n",
    "        color_column: str = \"color\",\n",
    "    ) -> None:\n",
    "\n",
    "        \"\"\"Add a column to the details dataframe with a color for each track\"\"\"\n",
    "\n",
    "        from PIL import ImageColor\n",
    "\n",
    "        if color_by:\n",
    "            if isinstance(color_by, str):\n",
    "                color_by = [color_by]\n",
    "\n",
    "            assert all([c in self.details.columns for c in color_by]), f\"Color-By columns {color_by} missing\"  # type: ignore\n",
    "\n",
    "            try:\n",
    "                # Get a pallette with enough colors for the unique groups in the details\n",
    "                n_colors = len(self.details[color_by].drop_duplicates())\n",
    "                colors = sns.color_palette(pallet, n_colors=n_colors).as_hex()  # type: ignore\n",
    "\n",
    "                # Assign a color to each group\n",
    "                color_dict = {}\n",
    "                for i, group in enumerate(\n",
    "                    self.details[color_by].drop_duplicates().itertuples()\n",
    "                ):\n",
    "                    color_dict[tuple([getattr(group, c) for c in color_by])] = colors[i]  # type: ignore\n",
    "\n",
    "                # Add a column to the details dataframe with the color for each track\n",
    "                self.details[\"color\"] = self.details[color_by].apply(\n",
    "                    lambda row: ImageColor.getrgb(color_dict[tuple([c for c in row])]),\n",
    "                    axis=1,\n",
    "                )\n",
    "\n",
    "            except NameError:\n",
    "                raise NameError(\n",
    "                    \"Pallette not found. Try one of the following: 'tab20', 'tab20b', 'tab20c'\"\n",
    "                )\n",
    "\n",
    "        elif color_column:\n",
    "\n",
    "            assert (\n",
    "                color_column in self.details.columns\n",
    "            ), f\"Color column {color_column} missing\"\n",
    "\n",
    "            colors = []\n",
    "            for i, color in enumerate(self.details[color_column]):\n",
    "                if isinstance(color, tuple):\n",
    "                    c = color\n",
    "                elif isinstance(color, str):\n",
    "                    if color.startswith(\"#\"):\n",
    "                        c = ImageColor.getrgb(color)\n",
    "                    else:\n",
    "                        c = color.split(\",\")\n",
    "                        c = tuple([int(x) for x in c])\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        f\"Color column {color_column} must be a tuple or string\"\n",
    "                    )\n",
    "\n",
    "                colors.append(c)\n",
    "\n",
    "            self.details[\"color\"] = colors\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def _add_subgroup_definitions_to_df(\n",
    "        self, df: pd.DataFrame, subgroup_by: List[str] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Add a column to the details dataframe with a `trackhub.SubGroupDefinition` for each track\"\"\"\n",
    "\n",
    "        assert all(\n",
    "            [c in df.columns for c in subgroup_by]\n",
    "        ), f\"Subgroup-By columns {subgroup_by} missing\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # Loop through all columns provided and generate a subgroup definition for each\n",
    "        subgroup_definitions = []\n",
    "        for column in subgroup_by:\n",
    "            # Get a list of unique values in the column\n",
    "            unique_values = df[column].unique()\n",
    "            subgroup_definition = trackhub.SubGroupDefinition(\n",
    "                name=column,\n",
    "                label=column,\n",
    "                mapping={value: value for value in unique_values},\n",
    "            )\n",
    "            subgroup_definitions.append(subgroup_definition)\n",
    "\n",
    "        # Add a column to the details dataframe with the subgroup definition for each track\n",
    "        df[\"subgroup_names\"] = [\n",
    "            tuple([col for col in subgroup_by]) for i in range(df.shape[0])\n",
    "        ]\n",
    "        df[\"subgroup_definition\"] = [subgroup_definitions for i in range(df.shape[0])]\n",
    "        return df\n",
    "\n",
    "    def _add_subgroupings(\n",
    "        self, supergroup_by: List[str] = None, subgroup_by: List[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Add a column to the details dataframe with a `trackhub.SubGroupDefinition` for each track.\n",
    "\n",
    "        If `supergroup_by` is provided, the subgroup definitions will be added to the dataframe\n",
    "        grouped by the supergroup columns.\n",
    "\n",
    "        If `supergroup_by` is not provided, the subgroup definitions will be added to the dataframe\n",
    "        as a single group.\n",
    "        \"\"\"\n",
    "\n",
    "        if subgroup_by:\n",
    "\n",
    "            assert all(\n",
    "                [c in self.details.columns for c in subgroup_by]\n",
    "            ), f\"Subgroup-By columns {subgroup_by} missing\"\n",
    "\n",
    "            if supergroup_by:\n",
    "                assert not any(\n",
    "                    subgroup in supergroup_by for subgroup in subgroup_by\n",
    "                ), f\"SubGroup columns {subgroup_by} cannot be in SuperGroup columns {supergroup_by}\"\n",
    "\n",
    "                self.details = self.details.groupby(supergroup_by).apply(\n",
    "                    self._add_subgroup_definitions_to_df, subgroup_by=subgroup_by\n",
    "                )\n",
    "            else:\n",
    "                self.details = self._add_subgroup_definitions_to_df(\n",
    "                    self.details, subgroup_by=subgroup_by\n",
    "                )\n",
    "\n",
    "    def _get_super_tracks(self) -> Dict[str, trackhub.SuperTrack]:\n",
    "        \"\"\"Generate a dictionary of SuperTracks from the details dataframe\"\"\"\n",
    "\n",
    "        if self._supertrack_columns:\n",
    "            assert all(\n",
    "                [c in self.details.columns for c in self._supertrack_columns]\n",
    "            ), f\"SuperTrack columns {self._supertrack_columns} missing\"\n",
    "\n",
    "            supertracks = dict()\n",
    "            for grouping, df in self.details.groupby(self._supertrack_columns):\n",
    "                supertracks[grouping] = trackhub.SuperTrack(\n",
    "                    name=\"_\".join(grouping),\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            supertracks = dict()\n",
    "\n",
    "        return supertracks\n",
    "\n",
    "    def _add_supertrack_indicators(self):\n",
    "        \"\"\"Add a column to the details dataframe with a SuperTrack indicator for each track\"\"\"\n",
    "\n",
    "        if self._supertrack_columns:\n",
    "            assert all(\n",
    "                [c in self.details.columns for c in self._supertrack_columns]\n",
    "            ), f\"SuperTrack columns {self._supertrack_columns} missing\"\n",
    "\n",
    "            self.details[\"supertrack\"] = self.details[self._supertrack_columns].apply(\n",
    "                lambda row: \"_\".join(row), axis=1\n",
    "            )\n",
    "\n",
    "    def _get_composite_tracks(self) -> Dict[str, trackhub.CompositeTrack]:\n",
    "        \"\"\"Generate a dictionary of CompositeTracks from the details dataframe\"\"\"\n",
    "\n",
    "        composite_tracks = dict()\n",
    "        if \"supertrack\" in self.details.columns:\n",
    "            for grouping, df in self.details.groupby([\"supertrack\", \"ext\"]):\n",
    "\n",
    "                subgroupings = df.iloc[df[\"subgroup_names\"].drop_duplicates().index, :][\n",
    "                    \"subgroup_definition\"\n",
    "                ]\n",
    "                dimensions = dict(\n",
    "                    zip(\n",
    "                        [f\"dim{d}\" for d in [\"X\", \"Y\", \"A\", \"B\", \"C\", \"D\"]],\n",
    "                        subgroupings,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                composite = trackhub.CompositeTrack(\n",
    "                    name=\"_\".join(grouping) if isinstance(grouping, tuple) else grouping,\n",
    "                    tracktype=grouping[1],\n",
    "                    dimensions=\" \".join([f\"{k}={v}\" for k, v in dimensions.items()])\n",
    "                    if dimensions\n",
    "                    else None,\n",
    "                    sortOrder=\" \".join([f\"{k}=+\" for k in subgroupings]),\n",
    "                    visibility=\"hide\",\n",
    "                    dragAndDrop=\"subTracks\",\n",
    "                    allButtonPair=\"off\",\n",
    "                )\n",
    "\n",
    "                self.super_tracks[grouping[0]].add_tracks(composite)\n",
    "                composite_tracks[grouping] = composite\n",
    "\n",
    "        elif self._subgroup_columns:\n",
    "            for grouping, df in self.details.groupby([\"ext\"]):\n",
    "                composite = trackhub.CompositeTrack(\n",
    "                    name=\"_\".join(grouping) if isinstance(grouping, tuple) else grouping,\n",
    "                    tracktype=grouping,\n",
    "                    visibility=\"hide\",\n",
    "                    dragAndDrop=\"subTracks\",\n",
    "                    allButtonPair=\"off\",\n",
    "                )\n",
    "\n",
    "                composite_tracks[grouping] = composite\n",
    "        \n",
    "        else:\n",
    "            composite_tracks = dict()\n",
    "\n",
    "        return composite_tracks\n",
    "\n",
    "    def _add_composite_track_indicators(self):\n",
    "        \"\"\"Add a column to the details dataframe with a CompositeTrack indicator for each track\"\"\"\n",
    "\n",
    "        if self.composite_tracks:\n",
    "            composite_columns = self._supertrack_columns if self._supertrack_columns else []\n",
    "            composite_columns.append(\"ext\")\n",
    "\n",
    "            self.details[\"composite\"] = self.details.loc[:, composite_columns].apply(\n",
    "                lambda row: \"_\".join(row), axis=1\n",
    "            )\n",
    "\n",
    "    def _get_overlay_tracks(self):\n",
    "        \"\"\"Generate a dictionary of OverlayTracks from the details dataframe\"\"\"\n",
    "\n",
    "        if self._overlay_columns:\n",
    "            assert all(\n",
    "                [c in self.details.columns for c in self._overlay_columns]\n",
    "            ), f\"Overlay columns {self._overlay_columns} missing\"\n",
    "\n",
    "            overlay_tracks = dict()\n",
    "\n",
    "            if \"supertrack\" in self.details.columns:\n",
    "\n",
    "                for grouping, df in self.details.groupby(\n",
    "                    [\"supertrack\", *self._overlay_columns]\n",
    "                ):\n",
    "                    overlay = trackhub.AggregateTrack(\n",
    "                        aggregate=\"transparentOverlay\",\n",
    "                        name=\"_\".join(grouping) if isinstance(grouping, tuple) else grouping,\n",
    "                    )\n",
    "\n",
    "                    self.super_tracks[grouping[0]].add_tracks(overlay)\n",
    "                    overlay_tracks[grouping] = overlay\n",
    "\n",
    "            else:\n",
    "                for grouping, df in self.details.groupby(self._overlay_columns):\n",
    "                    overlay = trackhub.AggregateTrack(\n",
    "                        aggregate=\"transparentOverlay\",\n",
    "                        name=\"_\".join(grouping) if isinstance(grouping, tuple) else grouping,\n",
    "                    )\n",
    "                    overlay_tracks[grouping] = overlay\n",
    "\n",
    "        else:\n",
    "            overlay_tracks = dict()\n",
    "\n",
    "        return overlay_tracks\n",
    "\n",
    "    def _add_overlay_track_indicators(self):\n",
    "        \"\"\"Add a column to the details dataframe with an OverlayTrack indicator for each track\"\"\"\n",
    "\n",
    "        if self._overlay_columns:\n",
    "\n",
    "            overlay_columns = (\n",
    "                self._supertrack_columns if self._supertrack_columns else []\n",
    "            )\n",
    "            overlay_columns.extend(self._overlay_columns)\n",
    "\n",
    "            self.details[\"overlay\"] = self.details.loc[:, overlay_columns].apply(\n",
    "                lambda row: \"_\".join(row), axis=1\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "class HubGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        hub_name: str,\n",
    "        genome: str,\n",
    "        track_design: HubDesign,\n",
    "        outdir: pathlib.Path,\n",
    "        description_url_path: pathlib.Path = None,\n",
    "        hub_email: str = \"\",\n",
    "        custom_genome: bool = False,\n",
    "        genome_twobit: pathlib.Path = None,\n",
    "        genome_organism: str = None,\n",
    "        genome_default_position: str = \"chr1:10000-20000\",\n",
    "    ):\n",
    "\n",
    "        # Basic parameters for hub creation\n",
    "        self.hub_name = hub_name\n",
    "        self.genome_name = genome\n",
    "        self.track_design = track_design\n",
    "        self.outdir = outdir\n",
    "        self.custom_genome = custom_genome\n",
    "        self.description_url_path = description_url_path\n",
    "\n",
    "        # Parameters for custom genomes\n",
    "        self._genome_twobit = genome_twobit\n",
    "        self._genome_organism = genome_organism\n",
    "        self._genome_default_position = genome_default_position\n",
    "\n",
    "        # Create the basic hub\n",
    "        self._hub = trackhub.Hub(\n",
    "            hub_name, short_label=hub_name, long_label=hub_name, email=hub_email\n",
    "        )\n",
    "        \n",
    "        self.trackdb = trackhub.TrackDb()\n",
    "        _genome = self._get_genome_file()  # type: ignore\n",
    "        _genomes_file = trackhub.GenomesFile()\n",
    "\n",
    "        # Add these to the hub\n",
    "        _genome.add_trackdb(self.trackdb)\n",
    "        self._hub.add_genomes_file(_genomes_file)\n",
    "        _genomes_file.add_genome(_genome)\n",
    "\n",
    "        self._add_tracks_to_hub()\n",
    "\n",
    "    def _add_tracks_to_hub(self) -> None:\n",
    "        # Loop through each entry in the details dataframe\n",
    "        \n",
    "        for row in self.track_design.details.itertuples():\n",
    "\n",
    "            # If the row has a \"composite\" attribute\n",
    "            if hasattr(row, \"composite\"):\n",
    "                composite_track = self.track_design.composite_tracks[row.composite]\n",
    "                # Create a new track and add it as a subtrack to the composite track\n",
    "                track = self._get_track(row, suffix=f\"_{row.composite}\")\n",
    "                composite_track.add_subtrack(track)\n",
    "\n",
    "            # If the row has an \"overlay\" attribute\n",
    "            elif hasattr(row, \"overlay\"):\n",
    "                overlay_track = self.track_design.overlay_tracks[row.overlay]\n",
    "                # Create a new track and add it to the overlay track\n",
    "                track = self._get_track(row, suffix=f\"_{row.overlay}\")\n",
    "                overlay_track.add_tracks(track)\n",
    "\n",
    "            # If the row doesn't have a \"supertrack\" attribute\n",
    "            elif not hasattr(row, \"supertrack\"):\n",
    "                # Create a new track and add it to the trackdb\n",
    "                track = self._get_track(row)\n",
    "                self.trackdb.add_tracks(track)\n",
    "\n",
    "        # Add the supertracks or composite/overlay tracks to the trackdb\n",
    "        if self.track_design.super_tracks:\n",
    "            tracks = self.track_design.super_tracks.values()\n",
    "            \n",
    "            # Ensure the composite and/or overlay tracks have the group attribute set\n",
    "            if self.custom_genome:\n",
    "                for t in [*self.track_design.composite_tracks.values(), *self.track_design.overlay_tracks.values()]:\n",
    "                    t.add_params(group=self._hub.hub)\n",
    "\n",
    "        else:\n",
    "            tracks = [*self.track_design.composite_tracks.values(), *self.track_design.overlay_tracks.values()]\n",
    "\n",
    "        for track in tracks:\n",
    "            # Add group if custom genome\n",
    "            if self.custom_genome:\n",
    "                track.add_params(group=self._hub.hub)\n",
    "            self.trackdb.add_tracks(track)\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_track(self, track: namedtuple, suffix: str = \"\") -> trackhub.Track:\n",
    "        \"\"\"Generate a trackhub.Track object from a row in the details dataframe\"\"\"\n",
    "\n",
    "\n",
    "        extra_kwargs = dict()\n",
    "        if hasattr(track, \"color\"):\n",
    "            extra_kwargs[\"color\"] = \",\".join([str(x) for x in track.color])\n",
    "        \n",
    "        if hasattr(track, \"subgroup_names\"):\n",
    "            extra_kwargs[\"subgroups\"] = {subgroup_name: getattr(track, subgroup_name) for subgroup_name in track.subgroup_names}\n",
    "\n",
    "        if self.custom_genome:\n",
    "            extra_kwargs[\"group\"] = self._hub.hub\n",
    "        \n",
    "        return  trackhub.Track(\n",
    "                name=\"\".join([trackhub.helpers.sanitize(track.name), suffix]),\n",
    "                shortLabel=\" \".join(re.split(r\"[.|_|\\s+|-]\", track.name)),\n",
    "                longLabel=\" \".join(re.split(r\"[.|_|\\s+|-]\", track.name)),\n",
    "                source=str(track.path),\n",
    "                autoScale=\"on\",\n",
    "                tracktype=track.ext,\n",
    "                windowingFunction=\"mean\",\n",
    "                **extra_kwargs,\n",
    "               \n",
    "            )\n",
    "      \n",
    "    def _get_genome_file(self) -> trackhub.Genome:\n",
    "\n",
    "        if not self.custom_genome:\n",
    "            genome = trackhub.Genome(self.genome_name)\n",
    "            groups_file = None\n",
    "        else:\n",
    "            genome = trackhub.Assembly(\n",
    "                genome=self.genome_name,\n",
    "                twobit_file=self._genome_twobit,\n",
    "                organism=self._genome_organism,\n",
    "                defaultPos=self._genome_default_position,\n",
    "            )\n",
    "\n",
    "            groups_file = trackhub.GroupsFile(\n",
    "                [\n",
    "                    trackhub.GroupDefinition(\n",
    "                        name=self.hub_name, priority=1, default_is_closed=False\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            genome.add_groups(groups_file)\n",
    "\n",
    "        return genome\n",
    "\n",
    "\n",
    "    def stage_hub(\n",
    "        self,\n",
    "    ):\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            trackhub.upload.stage_hub(self._hub, staging=tmpdir)\n",
    "\n",
    "            if self.description_url_path:\n",
    "                description_basename = os.path.basename(self.description_url_path)\n",
    "                with open(os.path.join(tmpdir, f\"{self._hub.hub}.hub.txt\"), \"a\") as hubtxt:\n",
    "                    hubtxt.write(\"\\n\")\n",
    "                    hubtxt.write(f\"descriptionUrl {self.genome_name}/{description_basename}\\n\")\n",
    "\n",
    "                shutil.copy(\n",
    "                    self.description_url_path,\n",
    "                    os.path.join(tmpdir, self.genome_name),\n",
    "                )\n",
    "\n",
    "            # Copy to the new location\n",
    "            shutil.copytree(\n",
    "                tmpdir,\n",
    "                self.outdir,\n",
    "                dirs_exist_ok=True,\n",
    "                symlinks=False,\n",
    "            )\n",
    "\n",
    "            subprocess.run([\"chmod\", \"-R\", \"2755\", self.outdir])\n",
    "            \n",
    "    \n",
    "   \n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bedToBigBed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m design \u001b[39m=\u001b[39m HubDesign\u001b[39m.\u001b[39;49mfrom_files(files, infer_attributes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, subgroup_by\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mantibody\u001b[39;49m\u001b[39m\"\u001b[39;49m], color_by\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mantibody\u001b[39;49m\u001b[39m\"\u001b[39;49m], convert_files\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m design\u001b[39m.\u001b[39mdetails\n",
      "\u001b[1;32m/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb Cell 9\u001b[0m in \u001b[0;36mHubDesign.from_files\u001b[0;34m(cls, files, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_files\u001b[39m(\u001b[39mcls\u001b[39m, files: List[pathlib\u001b[39m.\u001b[39mPath], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHubDesign\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m     hub_files \u001b[39m=\u001b[39m HubFiles(files, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m     extra_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m     \u001b[39mif\u001b[39;00m hub_files\u001b[39m.\u001b[39msubgroup_columns:\n",
      "\u001b[1;32m/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb Cell 9\u001b[0m in \u001b[0;36mHubFiles.__init__\u001b[0;34m(self, files, infer_subgroups, infer_attributes, deduplicate, convert_files, chromosome_sizes, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBED files detected. Please set convert_files=True to convert to BigBed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_tracks_to_ucsc_format(chrom_sizes\u001b[39m=\u001b[39;49mchromosome_sizes, outdir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m deduplicate:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfix_duplicate_names()\n",
      "\u001b[1;32m/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb Cell 9\u001b[0m in \u001b[0;36mHubFiles.convert_tracks_to_ucsc_format\u001b[0;34m(self, chrom_sizes, outdir)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m bed_files \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[\u001b[39m\"\u001b[39m\u001b[39mext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbed\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mfn\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mfor\u001b[39;00m bed_file \u001b[39min\u001b[39;00m bed_files:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mbedToBigBed\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m             \u001b[39mstr\u001b[39;49m(bed_file),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m             \u001b[39mstr\u001b[39;49m(chrom_sizes),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutdir\u001b[39m.\u001b[39;49mjoinpath(bed_file\u001b[39m.\u001b[39;49mwith_suffix(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m}\u001b[39;49;00m\u001b[39m.bigBed\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m         ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcbrglogin3.molbiol.ox.ac.uk/home/a/asmith/project_milne_group/Projects/ucsc_hub_maker/test_hub_creation.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m     )\n",
      "File \u001b[0;32m/Filers/home/a/asmith/mambaforge/envs/cc/lib/python3.10/subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m    499\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 501\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Filers/home/a/asmith/mambaforge/envs/cc/lib/python3.10/subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    966\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    967\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 969\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    970\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    971\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    972\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    973\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    974\u001b[0m                         errread, errwrite,\n\u001b[1;32m    975\u001b[0m                         restore_signals,\n\u001b[1;32m    976\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    977\u001b[0m                         start_new_session)\n\u001b[1;32m    978\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/Filers/home/a/asmith/mambaforge/envs/cc/lib/python3.10/subprocess.py:1845\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1843\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1844\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1845\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1846\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bedToBigBed'"
     ]
    }
   ],
   "source": [
    "design = HubDesign.from_files(files, infer_attributes=True, subgroup_by=[\"antibody\"], color_by=[\"antibody\"], convert_files=True)\n",
    "design.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = HubGenerator(\n",
    "    hub_name=\"test_hub\",\n",
    "    genome=\"hg38\",\n",
    "    track_design=design,\n",
    "    outdir=pathlib.Path(\"./test_hub_here\"),\n",
    "    hub_email=\"\",\n",
    "    custom_genome=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘test_hub_here’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r test_hub_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub.stage_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CapCruncher Environment",
   "language": "python",
   "name": "capcruncher"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
